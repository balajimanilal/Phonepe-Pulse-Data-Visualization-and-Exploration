{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated_insurance\n",
    "Path1=\"/Users/balajibm/New Folder/PhonePe/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "agg_insur_list= os.listdir(Path1)\n",
    "\n",
    "columns1={\"States\":[], \"Years\":[], \"Quarter\":[], \"Transaction_type\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in agg_insur_list:\n",
    "    cur_states = os.path.join(Path1, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                A = json.load(f)\n",
    "\n",
    "                for i in A[\"data\"][\"transactionData\"]:\n",
    "                    name=i[\"name\"]\n",
    "                    count=i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    amount=i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    columns1[\"Transaction_type\"].append(name)\n",
    "                    columns1[\"Transaction_count\"].append(count)\n",
    "                    columns1[\"Transaction_amount\"].append(amount)\n",
    "                    columns1[\"States\"].append(state)\n",
    "                    columns1[\"Years\"].append(year)\n",
    "                    columns1[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_insurance=pd.DataFrame(columns1)\n",
    "\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.title()\n",
    "aggre_insurance[\"States\"]=aggre_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Andaman & Nicobar', 'Tamil Nadu', 'Lakshadweep', 'Telangana',\n",
       "       'Manipur', 'Haryana', 'Gujarat', 'Sikkim', 'Delhi', 'West Bengal',\n",
       "       'Uttar Pradesh', 'Goa', 'Punjab', 'Arunachal Pradesh', 'Karnataka',\n",
       "       'Jammu & Kashmir', 'Maharashtra', 'Odisha', 'Madhya Pradesh',\n",
       "       'Rajasthan', 'Andhra Pradesh', 'Chandigarh', 'Kerala',\n",
       "       'Chhattisgarh', 'Tripura', 'Mizoram', 'Himachal Pradesh',\n",
       "       'Dadra and Nagar Haveli and Daman and Diu', 'Ladakh', 'Assam',\n",
       "       'Meghalaya', 'Uttarakhand', 'Puducherry', 'Bihar', 'Jharkhand',\n",
       "       'Nagaland'], dtype=object)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggre_insurance[\"States\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_insurance.sort_values(by=\"Transaction_count\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated_transactions\n",
    "\n",
    "Path2=\"/Users/balajibm/New Folder/PhonePe/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "agg_tran_list= os.listdir(Path2)\n",
    "\n",
    "columns2={\"States\":[], \"Years\":[], \"Quarter\":[], \"Transaction_type\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in agg_tran_list:\n",
    "    cur_states = os.path.join(Path2, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                B = json.load(f)\n",
    "\n",
    "                for i in B[\"data\"][\"transactionData\"]:\n",
    "                    name=i[\"name\"]\n",
    "                    count=i[\"paymentInstruments\"][0][\"count\"]\n",
    "                    amount=i[\"paymentInstruments\"][0][\"amount\"]\n",
    "                    columns2[\"Transaction_type\"].append(name)\n",
    "                    columns2[\"Transaction_count\"].append(count)\n",
    "                    columns2[\"Transaction_amount\"].append(amount)\n",
    "                    columns2[\"States\"].append(state)\n",
    "                    columns2[\"Years\"].append(year)\n",
    "                    columns2[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "aggre_transaction=pd.DataFrame(columns2)                    \n",
    "\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.title()\n",
    "aggre_transaction[\"States\"]=aggre_transaction[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_transaction[\"States\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated_User\n",
    "\n",
    "Path3=\"/Users/balajibm/New Folder/PhonePe/pulse/data/aggregated/user/country/india/state/\"\n",
    "agg_user_list= os.listdir(Path3)\n",
    "\n",
    "\n",
    "columns3={\"States\":[], \"Years\":[], \"Quarter\":[], \"Brands\":[], \"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "for state in agg_user_list:\n",
    "    cur_states = os.path.join(Path3, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                C = json.load(f)\n",
    "\n",
    "                try:\n",
    "                    for i in C[\"data\"][\"usersByDevice\"]:\n",
    "                        brand=i[\"brand\"]\n",
    "                        count=i[\"count\"]\n",
    "                        percentage=i[\"percentage\"]\n",
    "                        columns3[\"Brands\"].append(brand)\n",
    "                        columns3[\"Transaction_count\"].append(count)\n",
    "                        columns3[\"Percentage\"].append(percentage)\n",
    "                        columns3[\"States\"].append(state)\n",
    "                        columns3[\"Years\"].append(year)\n",
    "                        columns3[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "aggre_user=pd.DataFrame(columns3)\n",
    "\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace(\"-\",\" \")\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.title()\n",
    "aggre_user[\"States\"]=aggre_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggre_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map_Insurance\n",
    "Path4=\"/Users/balajibm/New Folder/PhonePe/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "map_insur_list= os.listdir(Path4)\n",
    "\n",
    "columns4={\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in map_insur_list:\n",
    "    cur_states = os.path.join(Path4, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                D = json.load(f)\n",
    "\n",
    "                for i in D[\"data\"][\"hoverDataList\"]:\n",
    "                                        name=i[\"name\"]\n",
    "                                        count=i[\"metric\"][0][\"count\"]\n",
    "                                        amount=i[\"metric\"][0][\"amount\"]\n",
    "                                        columns4[\"Districts\"].append(name)\n",
    "                                        columns4[\"Transaction_count\"].append(count)\n",
    "                                        columns4[\"Transaction_amount\"].append(amount)\n",
    "                                        columns4[\"States\"].append(state)\n",
    "                                        columns4[\"Years\"].append(year)\n",
    "                                        columns4[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_insurance=pd.DataFrame(columns4)\n",
    "\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.title()\n",
    "map_insurance[\"States\"]=map_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map_Transaction\n",
    "\n",
    "Path5=\"/Users/balajibm/New Folder/PhonePe/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "map_tran_list= os.listdir(Path5)\n",
    "\n",
    "columns5={\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in map_tran_list:\n",
    "    cur_states = os.path.join(Path5, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                E = json.load(f)\n",
    "\n",
    "                for i in E[\"data\"][\"hoverDataList\"]:\n",
    "                                        name=i[\"name\"]\n",
    "                                        count=i[\"metric\"][0][\"count\"]\n",
    "                                        amount=i[\"metric\"][0][\"amount\"]\n",
    "                                        columns5[\"Districts\"].append(name)\n",
    "                                        columns5[\"Transaction_count\"].append(count)\n",
    "                                        columns5[\"Transaction_amount\"].append(amount)\n",
    "                                        columns5[\"States\"].append(state)\n",
    "                                        columns5[\"Years\"].append(year)\n",
    "                                        columns5[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_transaction=pd.DataFrame(columns5)\n",
    "\n",
    "map_transaction[\"States\"]=map_transaction[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_transaction[\"States\"]=map_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "map_transaction[\"States\"]=map_transaction[\"States\"].str.title()\n",
    "map_transaction[\"States\"]=map_transaction[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map_User\n",
    "\n",
    "Path6=\"/Users/balajibm/New Folder/PhonePe/pulse/data/map/user/hover/country/india/state/\"\n",
    "map_user_list= os.listdir(Path6)\n",
    "\n",
    "columns6={\"States\":[], \"Years\":[], \"Quarter\":[], \"Districts\":[], \"RegisteredUsers\":[], \"AppOpens\":[]}\n",
    "\n",
    "for state in map_user_list:\n",
    "    cur_states = os.path.join(Path6, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                F = json.load(f)\n",
    "                \n",
    "                for i in F[\"data\"][\"hoverData\"].items():\n",
    "                    district=i[0]\n",
    "                    registeredUsers=i[1][\"registeredUsers\"]\n",
    "                    appOpens=i[1][\"appOpens\"]\n",
    "                    columns6[\"Districts\"].append(district)\n",
    "                    columns6[\"RegisteredUsers\"].append(registeredUsers)\n",
    "                    columns6[\"AppOpens\"].append(appOpens)\n",
    "                    columns6[\"States\"].append(state)\n",
    "                    columns6[\"Years\"].append(year)\n",
    "                    columns6[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "map_user=pd.DataFrame(columns6)\n",
    "\n",
    "map_user[\"States\"]=map_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "map_user[\"States\"]=map_user[\"States\"].str.replace(\"-\",\" \")\n",
    "map_user[\"States\"]=map_user[\"States\"].str.title()\n",
    "map_user[\"States\"]=map_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_Insurance\n",
    "Path7=\"/Users/balajibm/New Folder/PhonePe/pulse/data/top/insurance/country/india/state/\"\n",
    "top_insur_list= os.listdir(Path7)\n",
    "\n",
    "columns7={\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_insur_list:\n",
    "    cur_states = os.path.join(Path7, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                G = json.load(f)\n",
    "                \n",
    "                for i in G[\"data\"][\"pincodes\"]:\n",
    "                    entityname=i[\"entityName\"]\n",
    "                    count=i[\"metric\"][\"count\"]\n",
    "                    amount=i[\"metric\"][\"amount\"]\n",
    "                    columns7[\"Pincodes\"].append(entityname)\n",
    "                    columns7[\"Transaction_count\"].append(count)\n",
    "                    columns7[\"Transaction_amount\"].append(amount)\n",
    "                    columns7[\"States\"].append(state)\n",
    "                    columns7[\"Years\"].append(year)\n",
    "                    columns7[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_insurance=pd.DataFrame(columns7)\n",
    "\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace(\"-\",\" \")\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.title()\n",
    "top_insurance[\"States\"]=top_insurance[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_transaction\n",
    "Path8=\"/Users/balajibm/New Folder/PhonePe/pulse/data/top/transaction/country/india/state/\"\n",
    "top_tran_list= os.listdir(Path8)\n",
    "\n",
    "\n",
    "columns8={\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "for state in top_tran_list:\n",
    "    cur_states = os.path.join(Path8, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                H = json.load(f)\n",
    "                \n",
    "                for i in H[\"data\"][\"pincodes\"]:\n",
    "                    entityname=i[\"entityName\"]\n",
    "                    count=i[\"metric\"][\"count\"]\n",
    "                    amount=i[\"metric\"][\"amount\"]\n",
    "                    columns8[\"Pincodes\"].append(entityname)\n",
    "                    columns8[\"Transaction_count\"].append(count)\n",
    "                    columns8[\"Transaction_amount\"].append(amount)\n",
    "                    columns8[\"States\"].append(state)\n",
    "                    columns8[\"Years\"].append(year)\n",
    "                    columns8[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_transaction=pd.DataFrame(columns8)\n",
    "\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace(\"-\",\" \")\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.title()\n",
    "top_transaction[\"States\"]=top_transaction[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top_User\n",
    "Path9=\"/Users/balajibm/New Folder/PhonePe/pulse/data/top/user/country/india/state/\"\n",
    "top_user_list= os.listdir(Path9)\n",
    "\n",
    "columns9={\"States\":[], \"Years\":[], \"Quarter\":[], \"Pincodes\":[], \"RegisteredUsers\":[]}\n",
    "\n",
    "for state in top_user_list:\n",
    "    cur_states = os.path.join(Path9, state)  # Using os.path.join for path concatenation\n",
    "    if not os.path.isdir(cur_states):  # Check if it's a directory\n",
    "        continue\n",
    "    agg_year_list = os.listdir(cur_states)\n",
    "    \n",
    "    for year in agg_year_list:\n",
    "        cur_year = os.path.join(cur_states, year)\n",
    "        if not os.path.isdir(cur_year):\n",
    "            continue\n",
    "        agg_file_list = os.listdir(cur_year)\n",
    "        \n",
    "        for file in agg_file_list:\n",
    "            cur_file = os.path.join(cur_year, file)  # Correct path concatenation\n",
    "            with open(cur_file, \"r\") as f:\n",
    "                I = json.load(f)\n",
    "                \n",
    "                for i in I[\"data\"][\"pincodes\"]:\n",
    "                    entityname=i[\"name\"]\n",
    "                    registeredusers=i[\"registeredUsers\"]\n",
    "                    columns9[\"Pincodes\"].append(entityname)\n",
    "                    columns9[\"RegisteredUsers\"].append(registeredusers)\n",
    "                    columns9[\"States\"].append(state)\n",
    "                    columns9[\"Years\"].append(year)\n",
    "                    columns9[\"Quarter\"].append(int(file.strip(\".json\")))\n",
    "\n",
    "top_user=pd.DataFrame(columns9)\n",
    "\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace('andaman-&-nicobar-islands','Andaman & Nicobar')\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace(\"-\",\" \")\n",
    "top_user[\"States\"]=top_user[\"States\"].str.title()\n",
    "top_user[\"States\"]=top_user[\"States\"].str.replace('Dadra & Nagar Haveli & Daman & Diu','Dadra and Nagar Haveli and Daman and Diu')                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table Creation\n",
    "\n",
    "#SQL Connection\n",
    "mydb=psycopg2.connect(host=\"localhost\",\n",
    "                      user=\"postgres\",\n",
    "                      port=\"5432\",\n",
    "                      database=\"phonepe_data\",\n",
    "                      password=\"12345\")\n",
    "cursor=mydb.cursor()\n",
    "\n",
    "#Table - Aggregated_Insurance\n",
    "create_query_1='''CREATE TABLE if not exists aggregated_insurance(States varchar (255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Transaction_type varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_1)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_1='''INSERT INTO aggregated_insurance(States, Years, Quarter, Transaction_type, \n",
    "                                                    Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=aggre_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_1,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Aggregated_Transaction\n",
    "create_query_2='''CREATE TABLE if not exists aggregated_transaction(States varchar (255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Transaction_type varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_2)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_2='''INSERT INTO aggregated_transaction(States, Years, Quarter, Transaction_type, \n",
    "                                                    Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=aggre_transaction.values.tolist()\n",
    "cursor.executemany(insert_query_2,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Aggregated_User\n",
    "create_query_3='''CREATE TABLE if not exists aggregated_user(States varchar (255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Brands varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Percentage float)'''\n",
    "cursor.execute(create_query_3)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_3='''INSERT INTO aggregated_user(States, Years, Quarter, Brands, \n",
    "                                                    Transaction_count, Percentage)\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=aggre_user.values.tolist()\n",
    "cursor.executemany(insert_query_3,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Map_Insurance\n",
    "create_query_4='''CREATE TABLE if not exists map_insurance(States varchar (255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Districts varchar(255),\n",
    "                                                    Transaction_count bigint,\n",
    "                                                    Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_4)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_4='''INSERT INTO map_insurance(States, Years, Quarter, Districts, \n",
    "                                                    Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                                    values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=map_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_4,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Map_Transaction\n",
    "create_query_5='''CREATE TABLE if not exists map_transaction(States varchar (255),\n",
    "                                                            Years int,\n",
    "                                                            Quarter int,\n",
    "                                                            Districts varchar(255),\n",
    "                                                            Transaction_count bigint,\n",
    "                                                            Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_5)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_5='''INSERT INTO map_transaction(States, Years, Quarter, Districts, \n",
    "                                            Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=map_transaction.values.tolist()\n",
    "cursor.executemany(insert_query_5,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Map_User\n",
    "create_query_6='''CREATE TABLE if not exists map_user(States varchar (255),\n",
    "                                                    Years int,\n",
    "                                                    Quarter int,\n",
    "                                                    Districts varchar(255),\n",
    "                                                    RegisteredUsers bigint,\n",
    "                                                    AppOpens bigint)'''\n",
    "cursor.execute(create_query_6)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_6='''INSERT INTO map_user(States, Years, Quarter, Districts, \n",
    "                                            RegisteredUsers, AppOpens)\n",
    "                                                    \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=map_user.values.tolist()\n",
    "cursor.executemany(insert_query_6,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Top_Insurance\n",
    "create_query_7='''CREATE TABLE if not exists top_insurance(States varchar (255),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Pincodes int,\n",
    "                                                        Transaction_count bigint,\n",
    "                                                        Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_7)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_7='''INSERT INTO top_insurance(States, Years, Quarter, Pincodes, \n",
    "                                            Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=top_insurance.values.tolist()\n",
    "cursor.executemany(insert_query_7,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Top_Transaction\n",
    "create_query_8='''CREATE TABLE if not exists top_transaction(States varchar (255),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Pincodes int,\n",
    "                                                        Transaction_count bigint,\n",
    "                                                        Transaction_amount bigint)'''\n",
    "cursor.execute(create_query_8)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_8='''INSERT INTO top_transaction(States, Years, Quarter, Pincodes, \n",
    "                                            Transaction_count, Transaction_amount)\n",
    "                                                    \n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=top_transaction.values.tolist()\n",
    "cursor.executemany(insert_query_8,data)\n",
    "mydb.commit()\n",
    "\n",
    "#Table - Top_User\n",
    "create_query_9='''CREATE TABLE if not exists top_user(States varchar (255),\n",
    "                                                        Years int,\n",
    "                                                        Quarter int,\n",
    "                                                        Pincodes int,\n",
    "                                                        RegisteredUsers bigint\n",
    "                                                        )'''\n",
    "cursor.execute(create_query_9)\n",
    "mydb.commit()\n",
    "\n",
    "insert_query_9='''INSERT INTO top_user(States, Years, Quarter, Pincodes, \n",
    "                                            RegisteredUsers)\n",
    "                                                    \n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "\n",
    "data=top_user.values.tolist()\n",
    "cursor.executemany(insert_query_9,data)\n",
    "mydb.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
